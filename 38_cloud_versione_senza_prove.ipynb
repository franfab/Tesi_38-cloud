{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GB53n5NNKIN"
      },
      "source": [
        "\n",
        "38-Cloud è un dataset di immagini satellitari etichettate per la segmentazione delle nuvole. Il dataset è composto da 38 immagini Landsat 8 acquisite in diverse località del Nord America. Le immagini satellitari di 38-Cloud sono state ritagliate in tanti pezzetti più piccoli chiamati \"patch\" la cui dimensione è di 384 pixel per 384 pixel,in quanto consente di processare le immagini in modo più efficiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkYecYbmNRvO"
      },
      "source": [
        "Il dataset è stato suddiviso in due insiemi: training e testing.\n",
        "L'insieme di training contiene 8400 patch.\n",
        "L'insieme di testing contiene 9201 patch. Questi patch vengono utilizzati per valutare le prestazioni degli algoritmi di deep learning addestrati sull'insieme di training.\n",
        "Ogni patch ha 4 canali spettrali corrispondenti alle bande:\n",
        "1. Rosso (banda 4)\n",
        "2. Verde (banda 3)\n",
        "3. Blu (banda 2)\n",
        "4. Vicino infrarosso (banda 5)\n",
        "\n",
        "A differenza di altri dataset di immagini per computer vision, questi canali non sono combinati in un'unica immagine RGB.\n",
        "Invece, i canali sono salvati in cartelle separate corrispondenti alla banda spettrale.La separazione dei canali spettrali consente agli algoritmi di deep learning di apprendere relazioni più complesse tra le diverse bande. Questo può migliorare la precisione nella segmentazione delle nuvole rispetto alla combinazione dei canali in un'unica immagine RGB prima del training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3_IEVBnZfDx"
      },
      "source": [
        "# Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AZXvVNoNTzj"
      },
      "source": [
        "Inizio istallando Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbXN_NeTNV6h"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ztfw6vKNbia"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets  download sorour/38cloud-cloud-segmentation-in-satellite-images\n",
        "! unzip 38cloud-cloud-segmentation-in-satellite-images.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNH836QHZcSy"
      },
      "source": [
        "# Utili"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ws14hxiDZiTn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision import datasets, models, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import random\n",
        "import cv2\n",
        "import random\n",
        "import csv\n",
        "import seaborn as sns\n",
        "import albumentations as A\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RkcoKrJtVal",
        "outputId": "c971d838-6359-4ba9-e0d2-1ebd2051f950"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxUkB-HGtWyD"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "utile per la visualizzazione"
      ],
      "metadata": {
        "id": "hCcML-P7-abb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* batch_to_img-> Estrae l'immagine\n",
        "all'indice specificato, preleva i 3 canali (RGB) e li trasforma in NumPy array e sistema le dimensioni\n",
        "\n",
        "* predb_to_mask->Applica una funzione softmax alle predizioni per l'immagine selezionata per normalizzare le probabilità tra le classi e seleziona la probabilità maggiore grazie a argmax(0)"
      ],
      "metadata": {
        "id": "sEin9lfV_Ofp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_to_img(xb, idx):\n",
        "    img = np.array(xb[idx,0:3])\n",
        "    return img.transpose((1,2,0))\n",
        "\n",
        "def predb_to_mask(predb, idx):\n",
        "    p = torch.functional.F.softmax(predb[idx], 0)\n",
        "    return p.argmax(0).cpu()"
      ],
      "metadata": {
        "id": "9fH5NIHS-Y4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVYnxPpWbBiO"
      },
      "source": [
        "# CODICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48SyD-Gg_Xry"
      },
      "source": [
        "## DataSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lumI4wCO_eVt"
      },
      "source": [
        "Definisco combine, che mi serve per creare un dizionario files. Il concetto è che unisco le immagini riferite alla stessa immagine dei 4 canali piu la gt (vedo i percorsi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kmn61vsXa_de"
      },
      "outputs": [],
      "source": [
        "def combine(r_file: Path, g, b, nir, gt):\n",
        "        # Combina i percorsi dei file delle diverse bande in un dizionario\n",
        "        #il percorso r_file è come la base per crere il dizionario e\n",
        "        #per gli altri uso come base il nome del percorso rosso dove vado a cambaire\n",
        "        #\"red\" con la banda di interesse\n",
        "        files = {'red': r_file,\n",
        "                 'green':g/r_file.name.replace('red', 'green'),\n",
        "                 'blue': b/r_file.name.replace('red', 'blue'),\n",
        "                 'nir': nir/r_file.name.replace('red', 'nir'),\n",
        "                 'gt': gt/r_file.name.replace('red', 'gt')}\n",
        "\n",
        "        return files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkhQxKTDbqbi"
      },
      "outputs": [],
      "source": [
        "base_path = Path('38-Cloud_training')\n",
        "r=base_path/'train_red'\n",
        "g=base_path/'train_green'\n",
        "b=base_path/'train_blue'\n",
        "nir=base_path/'train_nir'\n",
        "gt=base_path/'train_gt'\n",
        "files = [combine(f, g, b, nir, gt) for f in r.iterdir() if not f.is_dir()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhV8179V_vcV"
      },
      "source": [
        "A questo punto una volta creato files, creo la CloudDataset. Già al suo interno c'è la trasforamzione in tensori utile per pytorch. Ho anche implementato *calc_mean_std* utile per il calcolo del mean e std che poi uso per normalizzare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Camg6ZRkdWEq"
      },
      "outputs": [],
      "source": [
        "class CloudDataset1(torch.utils.data.Dataset):\n",
        "    def __init__(self, files, transform=False, trasformN=None, pytorch=True):\n",
        "        super().__init__()\n",
        "        self.files = files\n",
        "        self.b=transform\n",
        "\n",
        "        if(self.b==True):\n",
        "          self.trasformazione = get_train_augmentations()\n",
        "\n",
        "        self.trasformN=trasformN\n",
        "        self.pytorch=pytorch\n",
        "\n",
        "    def __len__(self):\n",
        "        # Restituisce la lunghezza del dataset(numero dei file)\n",
        "        return len(self.files)\n",
        "\n",
        "\n",
        "    def open_as_array(self, idx, invert=False, include=False):\n",
        "        # Apre le immagini in posizione idx e le converto in un array NumPy utile per PyTorch\n",
        "\n",
        "        # Carica le bande RGB\n",
        "        rgb = np.stack([np.array(Image.open(self.files[idx]['red'])),\n",
        "                            np.array(Image.open(self.files[idx]['green'])),\n",
        "                            np.array(Image.open(self.files[idx]['blue'])),\n",
        "                           ], axis=2) #axis 2 indica di impilare lungo la terza dim dell'array\n",
        "        # il nostro rgb dovrebbe ora essere un array con 3 dimensioni di cui le prime due sono h e w e l'ultima rapprensenza\n",
        "        # il numero di canali in questo caso 3 (non c'è nir)\n",
        "\n",
        "        # Aggiunge la banda NIR all'array se richiesto (ora avrei 4 canali)\n",
        "        if include:\n",
        "            nir = np.expand_dims(np.array(Image.open(self.files[idx]['nir'])), 2)\n",
        "            rgb = np.concatenate([rgb, nir], axis=2)\n",
        "\n",
        "        #inverte gli assi dell'array per renderlo compatibile con la convenzione PyTorch (canali prima di altezza e larghezza)\n",
        "        if invert:\n",
        "            rgb = rgb.transpose((2,0,1))\n",
        "\n",
        "        # Normalizza i valori dell'array ho dovuto fare questo passaggio perchè avevo problemi con i valori e\n",
        "        # cercando informazioni online questa risulta la cosa migliore per normalizzare i dati dividendoli per il più\n",
        "        #alto valore possibile dell'array portando l'immagine tra 0 e 1\n",
        "        return rgb / np.iinfo(rgb.dtype).max\n",
        "\n",
        "\n",
        "    def open_mask(self, idx, add_dims=False):\n",
        "        # Apre le maschere come array numpy\n",
        "\n",
        "        # Carica la maschera e Converte i pixel con valore 255 in 1 e gli altri in 0\n",
        "        #ovvero  1 ai pixel corrispondenti alle nuvole e 0 altrimenti\n",
        "        mask = np.array(Image.open(self.files[idx]['gt']))\n",
        "        mask = np.where(mask==255, 1, 0)\n",
        "\n",
        "        # Aggiunge le dimensioni all'array se richiesto\n",
        "        return np.expand_dims(mask, 0) if add_dims else mask\n",
        "\n",
        "    def calc_mean_std(self, dataset):\n",
        "\n",
        "       # Inizializza le variabili per accumulare le statistiche\n",
        "      mean = torch.zeros(4)\n",
        "      std = torch.zeros(4)\n",
        "\n",
        "      # Itera su ogni batch di immagini\n",
        "      for i in range(len(dataset)):\n",
        "        images, _ = self[i]\n",
        "\n",
        "         # Converte l'array NumPy in un tensore PyTorch\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\")\n",
        "            images_tensor = torch.tensor(images)\n",
        "\n",
        "        # Calcola la media e la deviazione standard del batch\n",
        "        #dim->indica che si vuole calcolare la media lungo le prime tre dimensioni del tensore.\n",
        "        #il tensore contiene la media di tutti i valori in ogni canale per tutte le immagini nel batch. Per ogni canale c il valore in posizione c del tensore batch_mean è la media di tutti i valori nel canale c in tutte le immagini del batch.\n",
        "        batch_mean = torch.mean(images_tensor, dim=(0, 1, 2)) #h, w, batch\n",
        "        batch_std = torch.std(images_tensor, dim=(0, 1, 2))\n",
        "\n",
        "        # Accumula le statistiche per ogni canale\n",
        "        mean += batch_mean\n",
        "        std += batch_std\n",
        "\n",
        "\n",
        "      # Calcola la media e la deviazione standard finali\n",
        "      mean /= len(self)\n",
        "      std /= len(self)\n",
        "\n",
        "      return mean, std\n",
        "\n",
        "\n",
        "    def count_black_images(self):\n",
        "        # Conta quante immagini sono completamente nere\n",
        "        black_count = 0\n",
        "        for i in range(len(self)):\n",
        "            image = self.open_as_array(i, invert=True, include=True)\n",
        "            if np.all(image == 0):\n",
        "                black_count += 1\n",
        "        return black_count\n",
        "\n",
        "\n",
        "    def elimina_black(self, num_to_remove=None):\n",
        "        non_black_files = []\n",
        "        black_files = []\n",
        "\n",
        "        for i in range(len(self.files)):\n",
        "            image = self.open_as_array(i, invert=True, include=True)\n",
        "            if np.all(image == 0):\n",
        "                black_files.append(self.files[i])\n",
        "            else:\n",
        "                non_black_files.append(self.files[i])\n",
        "\n",
        "        # Stampa debug prima di eliminare\n",
        "        print(f\"Numero di immagini nere prima: {len(black_files)}\")\n",
        "        print(f\"Numero di immagini non nere prima: {len(non_black_files)}\")\n",
        "\n",
        "        if num_to_remove is not None and num_to_remove < len(black_files):\n",
        "            black_files = black_files[num_to_remove:]\n",
        "        else:\n",
        "            black_files = []\n",
        "\n",
        "        # Aggiorna self.files con le immagini non nere e le rimanenti immagini nere\n",
        "        self.files = non_black_files + black_files\n",
        "\n",
        "        # Stampa debug dopo l'eliminazione\n",
        "        print(f\"Numero di immagini nere dopo: {len(black_files)}\")\n",
        "        print(f\"Numero di immagini non nere dopo: {len(non_black_files)}\")\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "      x = self.open_as_array(idx, invert=self.pytorch, include=True)\n",
        "\n",
        "      y = self.open_mask(idx, add_dims=False)\n",
        "\n",
        "      if(self.b==True):\n",
        "        im=x.transpose(1,2,0)\n",
        "        augm=self.tranformazione(image =im, mask =y)\n",
        "        x=augm[\"image\"].transpose(2,0,1)\n",
        "        y=augm[\"mask\"]\n",
        "\n",
        "\n",
        "      x = torch.tensor(x, dtype=torch.float32)  # Cambiato a torch.float32\n",
        "\n",
        "\n",
        "      y = torch.tensor(y, dtype=torch.int64)  # Nessun cambiamento qui\n",
        "\n",
        "\n",
        "      if self.trasformN is not None:\n",
        "        x=self.trasformN(x)\n",
        "\n",
        "      return x, y\n",
        "\n",
        "\n",
        "    def get_black_image_indices(self):\n",
        "        black_indices = []\n",
        "        for i in range(len(self)):\n",
        "            image = self.open_as_array(i, invert=True, include=True)\n",
        "            if np.all(image == 0):\n",
        "                black_indices.append(i)\n",
        "        return black_indices\n",
        "\n",
        "\n",
        "    def __repr__(self):\n",
        "        # Rappresentazione testuale della classe\n",
        "        s = 'Dataset class with {} files'.format(self.__len__())\n",
        "\n",
        "        return s"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prova per eliminare le immagini nere"
      ],
      "metadata": {
        "id": "R2AI8w3S4c1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train=CloudDataset1(files)"
      ],
      "metadata": {
        "id": "vdASZvb_4fw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_ner=train.count_black_images()\n",
        "print(im_ner)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq4rdFde4msk",
        "outputId": "b5d23d27-cdc5-471c-8eb4-ac72525656b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "black_image_indices = train.get_black_image_indices()\n",
        "print(f'Indici delle immagini nere: {black_image_indices}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF52oF_M5meq",
        "outputId": "23cd27f5-d582-46ef-fc90-0dbb05fbc4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indici delle immagini nere: [2, 7, 9, 12, 13, 18, 19, 21, 23, 28, 31, 33, 37, 38, 40, 41, 42, 48, 50, 53, 55, 56, 58, 59, 60, 61, 62, 65, 76, 77, 82, 83, 87, 88, 89, 90, 91, 96, 97, 98, 100, 101, 106, 112, 113, 114, 116, 118, 119, 121, 123, 124, 125, 130, 131, 132, 133, 140, 142, 144, 146, 149, 152, 154, 155, 156, 158, 162, 166, 167, 170, 176, 179, 183, 184, 187, 188, 190, 194, 196, 197, 201, 212, 214, 220, 221, 222, 224, 226, 228, 231, 237, 241, 245, 248, 251, 253, 254, 256, 258, 262, 264, 268, 269, 274, 278, 280, 282, 283, 287, 288, 291, 294, 295, 298, 299, 301, 304, 306, 308, 315, 321, 325, 328, 335, 337, 340, 341, 342, 345, 351, 352, 360, 374, 376, 377, 379, 380, 384, 385, 389, 396, 398, 403, 406, 407, 412, 414, 416, 417, 418, 423, 429, 432, 433, 440, 441, 443, 444, 448, 449, 451, 452, 459, 462, 465, 466, 469, 472, 473, 474, 477, 479, 481, 483, 485, 491, 492, 493, 495, 501, 504, 514, 516, 519, 521, 522, 526, 527, 528, 544, 546, 548, 553, 557, 558, 559, 562, 563, 567, 569, 570, 573, 574, 579, 584, 586, 587, 594, 597, 598, 602, 603, 608, 609, 610, 612, 619, 625, 630, 632, 634, 636, 643, 645, 650, 651, 653, 657, 659, 661, 665, 669, 677, 679, 680, 681, 684, 686, 691, 697, 701, 706, 707, 709, 713, 717, 721, 722, 723, 726, 731, 736, 738, 740, 743, 745, 750, 753, 756, 759, 762, 763, 766, 767, 769, 770, 772, 773, 774, 779, 783, 785, 789, 791, 793, 797, 799, 800, 801, 803, 806, 807, 809, 810, 813, 814, 818, 819, 824, 825, 828, 835, 836, 837, 838, 850, 851, 855, 856, 863, 864, 865, 866, 868, 869, 870, 877, 879, 880, 881, 882, 884, 887, 891, 895, 897, 898, 905, 906, 909, 911, 915, 929, 931, 932, 933, 936, 937, 939, 940, 941, 943, 944, 956, 960, 961, 963, 965, 966, 967, 970, 971, 972, 975, 977, 978, 982, 983, 984, 990, 994, 1000, 1009, 1012, 1014, 1015, 1017, 1018, 1019, 1020, 1021, 1024, 1025, 1027, 1031, 1036, 1037, 1038, 1039, 1040, 1050, 1053, 1057, 1058, 1059, 1062, 1064, 1065, 1067, 1071, 1072, 1073, 1075, 1078, 1079, 1084, 1088, 1090, 1091, 1092, 1097, 1099, 1100, 1105, 1107, 1111, 1112, 1115, 1116, 1119, 1122, 1124, 1129, 1130, 1132, 1140, 1143, 1144, 1154, 1155, 1157, 1161, 1162, 1163, 1165, 1166, 1168, 1175, 1177, 1185, 1186, 1187, 1188, 1189, 1191, 1194, 1197, 1201, 1203, 1205, 1206, 1207, 1208, 1209, 1213, 1217, 1223, 1225, 1226, 1227, 1229, 1232, 1235, 1236, 1238, 1241, 1242, 1247, 1248, 1254, 1257, 1258, 1263, 1267, 1273, 1275, 1277, 1278, 1290, 1295, 1298, 1302, 1305, 1306, 1310, 1311, 1313, 1316, 1317, 1319, 1332, 1337, 1339, 1340, 1343, 1356, 1359, 1360, 1364, 1366, 1370, 1377, 1379, 1380, 1381, 1385, 1389, 1390, 1392, 1395, 1396, 1397, 1401, 1404, 1410, 1416, 1419, 1421, 1423, 1431, 1432, 1434, 1438, 1441, 1448, 1450, 1451, 1452, 1456, 1467, 1479, 1480, 1482, 1486, 1492, 1498, 1500, 1507, 1510, 1511, 1512, 1514, 1516, 1517, 1520, 1523, 1526, 1527, 1530, 1534, 1535, 1538, 1539, 1544, 1549, 1556, 1562, 1565, 1566, 1572, 1576, 1577, 1578, 1587, 1591, 1594, 1600, 1601, 1603, 1607, 1615, 1616, 1619, 1620, 1624, 1630, 1633, 1634, 1636, 1638, 1640, 1643, 1646, 1650, 1651, 1653, 1656, 1658, 1661, 1662, 1670, 1672, 1673, 1674, 1675, 1678, 1682, 1683, 1685, 1695, 1698, 1699, 1700, 1703, 1705, 1707, 1708, 1711, 1713, 1715, 1716, 1724, 1725, 1726, 1729, 1730, 1743, 1749, 1751, 1767, 1768, 1778, 1780, 1782, 1785, 1786, 1787, 1788, 1789, 1790, 1800, 1807, 1810, 1812, 1814, 1815, 1818, 1821, 1823, 1826, 1832, 1844, 1845, 1848, 1853, 1854, 1857, 1862, 1873, 1875, 1881, 1882, 1883, 1887, 1889, 1893, 1894, 1897, 1901, 1903, 1905, 1908, 1909, 1910, 1911, 1914, 1916, 1917, 1918, 1920, 1926, 1927, 1928, 1930, 1936, 1939, 1947, 1948, 1956, 1957, 1960, 1961, 1967, 1971, 1972, 1974, 1980, 1983, 1985, 1986, 1993, 1997, 2006, 2008, 2010, 2012, 2017, 2022, 2024, 2027, 2028, 2039, 2041, 2042, 2045, 2046, 2049, 2051, 2059, 2062, 2063, 2066, 2067, 2075, 2077, 2087, 2089, 2091, 2095, 2096, 2097, 2102, 2103, 2105, 2106, 2108, 2111, 2115, 2119, 2121, 2126, 2128, 2129, 2131, 2145, 2152, 2153, 2155, 2160, 2162, 2163, 2166, 2167, 2168, 2170, 2172, 2174, 2177, 2178, 2181, 2182, 2186, 2187, 2189, 2192, 2193, 2197, 2198, 2199, 2201, 2204, 2205, 2206, 2208, 2209, 2210, 2212, 2217, 2219, 2222, 2223, 2225, 2226, 2231, 2237, 2238, 2247, 2249, 2250, 2252, 2255, 2262, 2266, 2268, 2270, 2276, 2280, 2281, 2289, 2290, 2294, 2295, 2296, 2299, 2309, 2312, 2314, 2318, 2319, 2321, 2322, 2324, 2327, 2328, 2329, 2330, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2344, 2350, 2351, 2352, 2353, 2354, 2357, 2361, 2364, 2368, 2369, 2373, 2375, 2379, 2381, 2383, 2384, 2387, 2391, 2394, 2395, 2396, 2399, 2402, 2404, 2406, 2410, 2415, 2419, 2420, 2424, 2427, 2430, 2432, 2433, 2434, 2441, 2443, 2455, 2459, 2460, 2464, 2472, 2474, 2476, 2483, 2484, 2491, 2492, 2494, 2498, 2499, 2501, 2504, 2505, 2512, 2516, 2517, 2519, 2521, 2522, 2525, 2531, 2532, 2534, 2537, 2540, 2543, 2551, 2559, 2561, 2569, 2571, 2572, 2574, 2579, 2580, 2584, 2585, 2586, 2588, 2592, 2595, 2596, 2597, 2600, 2603, 2605, 2606, 2607, 2611, 2614, 2615, 2623, 2628, 2631, 2634, 2635, 2637, 2642, 2645, 2647, 2651, 2652, 2656, 2662, 2664, 2665, 2666, 2667, 2670, 2673, 2674, 2675, 2679, 2683, 2684, 2688, 2690, 2691, 2692, 2695, 2697, 2700, 2702, 2703, 2705, 2706, 2713, 2714, 2718, 2719, 2720, 2721, 2723, 2724, 2727, 2731, 2737, 2740, 2741, 2744, 2748, 2749, 2752, 2755, 2756, 2759, 2760, 2767, 2769, 2775, 2776, 2777, 2779, 2780, 2784, 2785, 2789, 2793, 2794, 2799, 2802, 2804, 2806, 2807, 2813, 2817, 2818, 2820, 2824, 2825, 2830, 2832, 2834, 2836, 2837, 2838, 2839, 2844, 2845, 2849, 2851, 2853, 2854, 2855, 2856, 2861, 2863, 2864, 2865, 2866, 2875, 2876, 2878, 2880, 2881, 2882, 2883, 2891, 2893, 2896, 2903, 2905, 2906, 2909, 2913, 2915, 2919, 2925, 2926, 2930, 2932, 2935, 2941, 2947, 2949, 2953, 2954, 2956, 2960, 2961, 2962, 2964, 2973, 2974, 2981, 2986, 2988, 2994, 2995, 2997, 3007, 3010, 3012, 3023, 3026, 3030, 3033, 3037, 3040, 3041, 3043, 3047, 3050, 3053, 3054, 3061, 3063, 3065, 3066, 3068, 3069, 3070, 3071, 3075, 3076, 3081, 3082, 3085, 3087, 3091, 3092, 3093, 3094, 3106, 3107, 3110, 3111, 3113, 3114, 3116, 3117, 3118, 3122, 3124, 3125, 3128, 3131, 3132, 3134, 3137, 3141, 3142, 3145, 3146, 3153, 3155, 3158, 3159, 3161, 3165, 3166, 3168, 3175, 3177, 3178, 3180, 3183, 3184, 3190, 3191, 3192, 3193, 3194, 3202, 3206, 3207, 3215, 3229, 3233, 3234, 3235, 3237, 3238, 3245, 3247, 3251, 3257, 3258, 3259, 3261, 3262, 3263, 3264, 3266, 3273, 3275, 3278, 3280, 3281, 3283, 3284, 3285, 3286, 3287, 3289, 3291, 3293, 3296, 3297, 3302, 3304, 3306, 3309, 3311, 3313, 3316, 3317, 3318, 3320, 3326, 3330, 3331, 3333, 3337, 3348, 3349, 3354, 3365, 3367, 3372, 3374, 3375, 3379, 3387, 3389, 3390, 3394, 3397, 3404, 3408, 3410, 3412, 3413, 3414, 3415, 3417, 3421, 3423, 3424, 3429, 3430, 3433, 3435, 3436, 3440, 3445, 3448, 3451, 3453, 3455, 3459, 3462, 3467, 3473, 3475, 3479, 3480, 3500, 3504, 3507, 3508, 3510, 3511, 3512, 3518, 3521, 3522, 3523, 3527, 3530, 3531, 3534, 3536, 3540, 3543, 3544, 3545, 3549, 3552, 3554, 3556, 3557, 3563, 3570, 3575, 3576, 3577, 3579, 3580, 3592, 3594, 3603, 3604, 3610, 3612, 3613, 3615, 3618, 3629, 3630, 3631, 3635, 3638, 3645, 3648, 3649, 3652, 3655, 3656, 3657, 3659, 3660, 3665, 3670, 3671, 3673, 3676, 3679, 3681, 3682, 3683, 3689, 3691, 3694, 3695, 3698, 3700, 3703, 3704, 3708, 3709, 3710, 3712, 3716, 3720, 3721, 3722, 3723, 3724, 3728, 3735, 3739, 3742, 3747, 3748, 3749, 3750, 3755, 3759, 3760, 3764, 3765, 3767, 3772, 3773, 3774, 3775, 3779, 3791, 3794, 3804, 3805, 3807, 3808, 3809, 3814, 3815, 3816, 3818, 3821, 3822, 3828, 3830, 3833, 3837, 3838, 3844, 3846, 3847, 3849, 3850, 3851, 3852, 3853, 3854, 3857, 3858, 3861, 3864, 3869, 3871, 3872, 3873, 3876, 3881, 3883, 3884, 3888, 3894, 3896, 3900, 3907, 3908, 3914, 3922, 3924, 3927, 3931, 3933, 3937, 3938, 3941, 3942, 3945, 3949, 3950, 3956, 3957, 3959, 3963, 3966, 3967, 3975, 3980, 3985, 3987, 3990, 3994, 4002, 4006, 4007, 4008, 4014, 4015, 4016, 4017, 4022, 4024, 4034, 4036, 4041, 4050, 4051, 4059, 4062, 4067, 4068, 4076, 4079, 4080, 4082, 4085, 4089, 4096, 4098, 4099, 4100, 4104, 4113, 4114, 4124, 4129, 4130, 4138, 4140, 4141, 4144, 4147, 4149, 4150, 4152, 4153, 4156, 4157, 4158, 4161, 4165, 4167, 4171, 4172, 4173, 4176, 4178, 4183, 4185, 4188, 4190, 4197, 4199, 4200, 4205, 4207, 4208, 4212, 4213, 4214, 4219, 4226, 4229, 4231, 4233, 4236, 4242, 4246, 4247, 4248, 4251, 4253, 4254, 4255, 4263, 4265, 4270, 4272, 4279, 4281, 4282, 4283, 4284, 4287, 4288, 4291, 4293, 4296, 4297, 4298, 4303, 4306, 4309, 4311, 4315, 4317, 4318, 4323, 4330, 4332, 4333, 4336, 4342, 4344, 4347, 4349, 4351, 4354, 4355, 4356, 4359, 4361, 4362, 4363, 4365, 4371, 4378, 4383, 4389, 4394, 4399, 4403, 4404, 4409, 4415, 4419, 4421, 4423, 4434, 4436, 4442, 4445, 4446, 4448, 4450, 4454, 4468, 4472, 4475, 4478, 4480, 4481, 4485, 4487, 4491, 4492, 4498, 4502, 4503, 4506, 4507, 4515, 4517, 4520, 4523, 4527, 4532, 4537, 4539, 4543, 4544, 4545, 4549, 4552, 4554, 4561, 4565, 4566, 4567, 4569, 4570, 4571, 4575, 4579, 4580, 4583, 4584, 4586, 4587, 4588, 4590, 4594, 4602, 4603, 4605, 4607, 4609, 4610, 4612, 4614, 4615, 4623, 4624, 4627, 4630, 4634, 4640, 4642, 4646, 4648, 4652, 4655, 4659, 4660, 4661, 4662, 4664, 4666, 4670, 4672, 4673, 4674, 4675, 4677, 4679, 4683, 4684, 4685, 4686, 4687, 4688, 4694, 4695, 4697, 4699, 4701, 4702, 4703, 4705, 4710, 4712, 4717, 4718, 4719, 4723, 4727, 4732, 4733, 4734, 4743, 4744, 4750, 4752, 4753, 4754, 4757, 4761, 4763, 4764, 4766, 4767, 4770, 4772, 4773, 4776, 4777, 4778, 4784, 4787, 4790, 4800, 4804, 4814, 4816, 4817, 4819, 4820, 4823, 4824, 4830, 4832, 4833, 4834, 4835, 4837, 4844, 4847, 4850, 4855, 4858, 4860, 4861, 4863, 4864, 4866, 4870, 4873, 4876, 4879, 4883, 4886, 4887, 4889, 4890, 4894, 4895, 4898, 4900, 4904, 4905, 4912, 4913, 4916, 4921, 4925, 4926, 4927, 4928, 4930, 4931, 4932, 4934, 4941, 4946, 4947, 4949, 4950, 4956, 4958, 4965, 4968, 4971, 4976, 4980, 4986, 4994, 5002, 5004, 5006, 5010, 5014, 5022, 5027, 5029, 5033, 5035, 5038, 5042, 5047, 5049, 5051, 5053, 5057, 5058, 5060, 5062, 5068, 5080, 5081, 5084, 5090, 5092, 5093, 5096, 5097, 5098, 5103, 5107, 5109, 5110, 5116, 5117, 5121, 5126, 5127, 5128, 5129, 5139, 5142, 5147, 5150, 5152, 5156, 5157, 5167, 5169, 5174, 5176, 5183, 5185, 5186, 5188, 5190, 5191, 5203, 5209, 5210, 5216, 5218, 5222, 5223, 5227, 5231, 5232, 5233, 5234, 5236, 5238, 5239, 5245, 5246, 5247, 5248, 5254, 5258, 5262, 5265, 5268, 5269, 5270, 5272, 5273, 5276, 5278, 5280, 5282, 5283, 5285, 5287, 5288, 5290, 5291, 5292, 5296, 5298, 5301, 5305, 5306, 5309, 5316, 5320, 5324, 5329, 5332, 5333, 5335, 5336, 5342, 5343, 5345, 5348, 5350, 5352, 5356, 5362, 5363, 5364, 5369, 5374, 5376, 5378, 5383, 5384, 5385, 5387, 5388, 5392, 5393, 5395, 5399, 5400, 5401, 5405, 5407, 5408, 5409, 5412, 5413, 5414, 5415, 5418, 5419, 5420, 5423, 5426, 5431, 5432, 5433, 5437, 5440, 5443, 5445, 5451, 5454, 5456, 5459, 5461, 5467, 5473, 5474, 5483, 5485, 5489, 5494, 5495, 5497, 5505, 5508, 5509, 5510, 5512, 5519, 5520, 5521, 5522, 5523, 5527, 5532, 5535, 5537, 5541, 5542, 5543, 5544, 5546, 5550, 5551, 5555, 5556, 5558, 5560, 5561, 5563, 5570, 5573, 5574, 5575, 5583, 5589, 5591, 5592, 5598, 5600, 5601, 5606, 5612, 5613, 5616, 5617, 5625, 5626, 5628, 5630, 5632, 5634, 5639, 5643, 5644, 5646, 5654, 5655, 5658, 5659, 5661, 5664, 5665, 5666, 5669, 5674, 5676, 5680, 5686, 5689, 5694, 5695, 5696, 5698, 5700, 5703, 5708, 5710, 5714, 5717, 5727, 5733, 5734, 5735, 5739, 5740, 5743, 5744, 5750, 5753, 5756, 5757, 5759, 5766, 5768, 5771, 5772, 5776, 5780, 5782, 5783, 5789, 5790, 5793, 5798, 5799, 5804, 5807, 5809, 5811, 5813, 5814, 5817, 5818, 5823, 5827, 5828, 5829, 5834, 5845, 5846, 5854, 5855, 5858, 5859, 5860, 5866, 5868, 5869, 5872, 5873, 5875, 5877, 5878, 5884, 5894, 5896, 5897, 5899, 5906, 5907, 5908, 5909, 5910, 5911, 5912, 5915, 5917, 5924, 5925, 5926, 5927, 5928, 5929, 5932, 5933, 5937, 5938, 5942, 5943, 5946, 5949, 5950, 5957, 5958, 5962, 5967, 5968, 5970, 5971, 5972, 5979, 5985, 5986, 5989, 5991, 5993, 5997, 6001, 6003, 6005, 6007, 6009, 6014, 6018, 6020, 6025, 6026, 6028, 6029, 6031, 6037, 6042, 6043, 6045, 6048, 6052, 6054, 6055, 6056, 6058, 6059, 6062, 6063, 6066, 6067, 6068, 6072, 6074, 6076, 6078, 6086, 6087, 6093, 6096, 6097, 6100, 6101, 6103, 6106, 6107, 6109, 6120, 6127, 6128, 6129, 6138, 6140, 6144, 6145, 6146, 6147, 6148, 6158, 6160, 6162, 6164, 6170, 6173, 6176, 6178, 6179, 6182, 6185, 6193, 6196, 6199, 6206, 6208, 6210, 6211, 6212, 6215, 6217, 6220, 6225, 6226, 6232, 6235, 6240, 6253, 6256, 6261, 6262, 6264, 6269, 6273, 6274, 6280, 6282, 6286, 6287, 6288, 6291, 6292, 6293, 6297, 6300, 6307, 6312, 6313, 6314, 6316, 6321, 6322, 6323, 6324, 6329, 6332, 6333, 6338, 6340, 6341, 6344, 6351, 6361, 6365, 6372, 6374, 6376, 6378, 6383, 6388, 6390, 6395, 6398, 6403, 6404, 6405, 6408, 6410, 6412, 6413, 6414, 6415, 6416, 6418, 6419, 6423, 6434, 6441, 6452, 6454, 6457, 6458, 6462, 6463, 6464, 6469, 6470, 6478, 6480, 6484, 6488, 6493, 6498, 6504, 6505, 6507, 6509, 6511, 6514, 6516, 6526, 6528, 6534, 6536, 6542, 6544, 6549, 6551, 6552, 6553, 6554, 6560, 6561, 6566, 6567, 6568, 6576, 6578, 6584, 6586, 6588, 6591, 6595, 6600, 6603, 6604, 6608, 6611, 6612, 6615, 6618, 6621, 6625, 6627, 6634, 6635, 6640, 6644, 6648, 6650, 6653, 6654, 6655, 6667, 6669, 6672, 6675, 6676, 6678, 6683, 6685, 6694, 6695, 6699, 6700, 6708, 6712, 6716, 6718, 6724, 6727, 6729, 6730, 6734, 6738, 6739, 6741, 6742, 6746, 6748, 6750, 6752, 6755, 6756, 6763, 6765, 6767, 6768, 6769, 6771, 6775, 6779, 6783, 6792, 6798, 6799, 6800, 6803, 6805, 6809, 6826, 6827, 6832, 6833, 6834, 6836, 6837, 6838, 6848, 6852, 6860, 6863, 6865, 6866, 6870, 6872, 6873, 6874, 6883, 6885, 6886, 6888, 6889, 6891, 6894, 6895, 6899, 6904, 6910, 6915, 6916, 6918, 6924, 6925, 6931, 6932, 6934, 6938, 6940, 6952, 6955, 6956, 6958, 6960, 6964, 6965, 6967, 6969, 6972, 6974, 6977, 6979, 6986, 6987, 6989, 6991, 6994, 6995, 6998, 7000, 7003, 7004, 7008, 7010, 7013, 7018, 7020, 7021, 7026, 7030, 7035, 7042, 7043, 7045, 7046, 7047, 7055, 7058, 7062, 7063, 7064, 7072, 7078, 7079, 7081, 7085, 7093, 7096, 7099, 7100, 7102, 7104, 7107, 7113, 7114, 7120, 7124, 7125, 7126, 7130, 7134, 7139, 7145, 7146, 7147, 7148, 7149, 7154, 7156, 7161, 7170, 7171, 7176, 7179, 7180, 7184, 7186, 7189, 7190, 7194, 7196, 7200, 7201, 7202, 7204, 7206, 7207, 7208, 7209, 7211, 7218, 7220, 7233, 7235, 7237, 7239, 7243, 7244, 7247, 7249, 7250, 7253, 7254, 7257, 7258, 7259, 7260, 7265, 7266, 7267, 7268, 7274, 7277, 7289, 7295, 7300, 7302, 7305, 7307, 7308, 7314, 7318, 7322, 7325, 7328, 7330, 7334, 7335, 7339, 7342, 7347, 7348, 7349, 7350, 7352, 7353, 7356, 7363, 7364, 7365, 7368, 7374, 7376, 7377, 7384, 7386, 7391, 7394, 7396, 7397, 7403, 7407, 7410, 7411, 7412, 7414, 7416, 7420, 7422, 7427, 7429, 7435, 7436, 7441, 7446, 7462, 7463, 7467, 7470, 7472, 7477, 7480, 7482, 7487, 7488, 7489, 7490, 7493, 7494, 7497, 7504, 7506, 7510, 7511, 7513, 7515, 7517, 7518, 7521, 7522, 7523, 7525, 7528, 7530, 7532, 7535, 7542, 7543, 7548, 7551, 7552, 7554, 7555, 7562, 7563, 7567, 7570, 7573, 7579, 7581, 7583, 7591, 7595, 7599, 7606, 7607, 7611, 7617, 7619, 7622, 7627, 7632, 7633, 7636, 7638, 7640, 7644, 7645, 7646, 7648, 7652, 7656, 7660, 7661, 7665, 7666, 7669, 7670, 7672, 7673, 7674, 7682, 7683, 7688, 7695, 7705, 7708, 7709, 7710, 7711, 7720, 7721, 7725, 7727, 7728, 7731, 7732, 7735, 7739, 7740, 7744, 7746, 7754, 7755, 7756, 7757, 7759, 7768, 7769, 7773, 7775, 7778, 7779, 7782, 7784, 7791, 7792, 7793, 7794, 7795, 7797, 7803, 7811, 7813, 7814, 7815, 7819, 7821, 7825, 7828, 7830, 7832, 7835, 7840, 7842, 7851, 7858, 7865, 7866, 7868, 7872, 7874, 7876, 7880, 7882, 7885, 7888, 7891, 7893, 7899, 7900, 7902, 7903, 7908, 7916, 7921, 7926, 7928, 7934, 7935, 7942, 7951, 7955, 7961, 7962, 7965, 7966, 7967, 7970, 7971, 7972, 7974, 7976, 7977, 7982, 7985, 7986, 7987, 7995, 7999, 8000, 8002, 8003, 8006, 8008, 8009, 8011, 8013, 8015, 8017, 8019, 8025, 8031, 8033, 8037, 8038, 8040, 8047, 8050, 8057, 8059, 8060, 8068, 8071, 8072, 8075, 8079, 8083, 8085, 8097, 8099, 8100, 8102, 8104, 8105, 8108, 8119, 8121, 8124, 8125, 8126, 8132, 8139, 8141, 8142, 8146, 8148, 8151, 8153, 8156, 8158, 8161, 8165, 8171, 8172, 8173, 8174, 8175, 8176, 8177, 8181, 8182, 8187, 8189, 8191, 8194, 8196, 8197, 8198, 8201, 8203, 8205, 8207, 8210, 8211, 8212, 8213, 8218, 8229, 8232, 8234, 8235, 8238, 8240, 8242, 8243, 8247, 8252, 8253, 8259, 8266, 8269, 8273, 8274, 8275, 8276, 8280, 8284, 8286, 8287, 8288, 8290, 8292, 8298, 8302, 8304, 8305, 8308, 8316, 8317, 8320, 8322, 8329, 8331, 8333, 8336, 8339, 8341, 8347, 8348, 8353, 8354, 8357, 8360, 8368, 8369, 8370, 8374, 8375, 8376, 8383, 8385, 8387, 8389, 8392]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.elimina_black()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huiYufIk-Fw-",
        "outputId": "4a52ee13-8c62-454f-8767-04b6d1884249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero di immagini nere prima: 2813\n",
            "Numero di immagini non nere prima: 5587\n",
            "Numero di immagini nere dopo: 0\n",
            "Numero di immagini non nere dopo: 5587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train.files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fJhxMjRu_nI",
        "outputId": "2b44cbe6-d517-4570-916b-ec7e8861bc10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### per salvare sul drive"
      ],
      "metadata": {
        "id": "lys7GYTNAGls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwjF833-AGN4",
        "outputId": "062de975-b549-4d81-bea7-2214b49b1912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root=\"/content/drive/MyDrive/Tesi/\""
      ],
      "metadata": {
        "id": "oIFh33RKAK-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(train.files, root+'flies')"
      ],
      "metadata": {
        "id": "z9t0p53Ap-7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files1=torch.load(root+\"files\")"
      ],
      "metadata": {
        "id": "ho-4klQxL0mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMyNUoDpBNBl"
      },
      "source": [
        "## Visualizzazioni Immagini del set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT1ps2lN-_hH"
      },
      "source": [
        "Visualizzo 5 immagini random per il validation e per il training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsRP7qmp--1C"
      },
      "outputs": [],
      "source": [
        "indici = random.sample(range(100), 5)\n",
        "\n",
        "# Crea una figura con 5 subplots\n",
        "fig, axes = plt.subplots(5, 2, figsize=(15, 25))\n",
        "\n",
        "# Itera sui 5 indici casuali\n",
        "for i, idx in enumerate(indici):\n",
        "    # Carica l'immagine e la maschera delle nuvole\n",
        "    img = train_set.open_as_array(idx)\n",
        "    mask = train_set.open_mask(idx)\n",
        "\n",
        "    # Visualizza l'immagine nel subplot corrispondente\n",
        "    axes[i, 0].imshow(img)\n",
        "    axes[i, 0].set_title(f'Image {idx}')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Visualizza la maschera delle nuvole nel subplot corrispondente\n",
        "    axes[i, 1].imshow(mask)\n",
        "    axes[i, 1].set_title(f'Mask {idx}')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezhLIUQc_EpN"
      },
      "outputs": [],
      "source": [
        "indici = random.sample(range(100), 5)\n",
        "\n",
        "# Crea una figura con 5 subplots\n",
        "fig, axes = plt.subplots(5, 2, figsize=(15, 25))\n",
        "\n",
        "# Itera sui 5 indici casuali\n",
        "for i, idx in enumerate(indici):\n",
        "    # Carica l'immagine e la maschera delle nuvole\n",
        "    img = val_set.open_as_array(idx)\n",
        "    mask = val_set.open_mask(idx)\n",
        "\n",
        "    # Visualizza l'immagine nel subplot corrispondente\n",
        "    axes[i, 0].imshow(img)\n",
        "    axes[i, 0].set_title(f'Image {idx}')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Visualizza la maschera delle nuvole nel subplot corrispondente\n",
        "    axes[i, 1].imshow(mask)\n",
        "    axes[i, 1].set_title(f'Mask {idx}')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmUt9UaXCyeg"
      },
      "source": [
        "## Creazione DataLoader e visualizzazione"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "senza immagine nere sto provando con 16 di batch"
      ],
      "metadata": {
        "id": "ZT7RXVjj44XF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yvg98J2ZC4EF"
      },
      "outputs": [],
      "source": [
        "train_loader = data.DataLoader(train_set, batch_size=8, shuffle=True)\n",
        "val_loader = data.DataLoader(val_set, batch_size=8, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-obsdmZEcy5"
      },
      "outputs": [],
      "source": [
        "indici = random.sample(range(15), 5)\n",
        "batch = next(iter(train_loader))\n",
        "images, masks = batch\n",
        "# Crea una figura con 5 subplots\n",
        "fig, axes = plt.subplots(5, 2, figsize=(15, 25))\n",
        "for i, idx in enumerate(indici):\n",
        "    # Carica l'immagine e la maschera delle nuvole\n",
        "    img = train_set.open_as_array(idx)\n",
        "    mask = train_set.open_mask(idx)\n",
        "\n",
        "    # Visualizza l'immagine nel subplot corrispondente\n",
        "    axes[i, 0].imshow(img)\n",
        "    axes[i, 0].set_title(f'Image {idx}')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Visualizza la maschera delle nuvole nel subplot corrispondente\n",
        "    axes[i, 1].imshow(mask)\n",
        "    axes[i, 1].set_title(f'Mask {idx}')\n",
        "    axes[i, 1].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtT6BvjNEdQa"
      },
      "outputs": [],
      "source": [
        "indici = random.sample(range(15), 5)\n",
        "batch = next(iter(val_loader))\n",
        "images, masks = batch\n",
        "# Crea una figura con 5 subplots\n",
        "fig, axes = plt.subplots(5, 2, figsize=(15, 25))\n",
        "for i, idx in enumerate(indici):\n",
        "    # Carica l'immagine e la maschera delle nuvole\n",
        "    img = train_set.open_as_array(idx)\n",
        "    mask = train_set.open_mask(idx)\n",
        "\n",
        "    # Visualizza l'immagine nel subplot corrispondente\n",
        "    axes[i, 0].imshow(img)\n",
        "    axes[i, 0].set_title(f'Image {idx}')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Visualizza la maschera delle nuvole nel subplot corrispondente\n",
        "    axes[i, 1].imshow(mask)\n",
        "    axes[i, 1].set_title(f'Mask {idx}')\n",
        "    axes[i, 1].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT_WjfIfGbEt"
      },
      "source": [
        "## U-Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKFlhLusFrMz"
      },
      "source": [
        "U-Net è una rete neurale convoluzionale sviluppata presso il Dipartimento di Informatica dell'Università di Friburgo per la segmentazione di immagini biomediche."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KuRGUkCF3uS"
      },
      "source": [
        "**Architettura**\n",
        "Si compone di un percorso contraente e di un percorso espansivo\n",
        "\n",
        "1. **Percorso di contrazione**: Questo percorso cattura i contesti dell'immagine. Comprende blocchi di down-sampling che riducono la dimensione spaziale dell'immagine mentre aumentano il numero di canali. In ogni blocco, viene applicata una convoluzione seguita da un'attivazione ReLU e da un pooling massimo.\n",
        "\n",
        "2. **Percorso di espansione** : Questo percorso ripristina la risoluzione spaziale e localizza le caratteristiche precise. Comprende blocchi di up-sampling che aumentano la dimensione spaziale dell'immagine mentre riducono il numero di canali. In ogni blocco, viene applicata una convoluzione trasposta seguita da un concatenamento con le caratteristiche corrispondenti dal percorso di contrazione, un ritaglio e un'attivazione ReLU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jtp8xYuyLtLT"
      },
      "source": [
        "*  **DoppiaConv**--->definisce un blocco base per U-Net, costituito da due strati convoluzionali 3x3 consecutivi con padding per mantenere le dimensioni spaziali.\n",
        "\n",
        "      * Uno strato convoluzionale (Conv2D) esegue un'operazione di convoluzione su un'immagine in ingresso. Questa operazione fa scorrere un kernel (filtro) di dimensioni fisse sull'immagine, calcolando un nuovo valore per ogni posizione del kernel. Il valore calcolato è la somma ponderata dei pixel dell'immagine all'interno del kernel, ponderata dai valori del kernel stesso\n",
        "      *  Questo kernel 3x3 si sposta sull'immagine in ingresso un pixel alla volta (stride=1) senza modificare le dimensioni dell'immagine in uscita (padding=1).\n",
        "      * nn.BatchNorm2d->Questo strato esegue la normalizzazione di batch sui canali dell'output della convoluzione. La normalizzazione di batch aiuta a stabilizzare l'addestramento della rete e migliorare le prestazioni.\n",
        "      * nn.ReLU-> La funzione ReLU introduce non linearità nella rete, aiutandola a imparare pattern complessi nei dati.\n",
        "\n",
        "\n",
        "UNET-> vera e propria rete UNET\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih61NEacGaZ9"
      },
      "outputs": [],
      "source": [
        "class DoppiaConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(DoppiaConv, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,3,1,1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1,1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.conv(x)\n",
        "\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, features=[64, 128, 256, 512]):\n",
        "      super(UNET, self).__init__()\n",
        "      #Crea un contenitore (ModuleList) per memorizzare gli strati di upsampling e di downsampling\n",
        "      self.ups=nn.ModuleList()\n",
        "      self.downs=nn.ModuleList()\n",
        "      #Crea uno strato di pooling massimo con dimensione del kernel di 2x2 e stride di 2 per il downsampling.\n",
        "      self.pool=nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "      #Down\n",
        "      for f in features:\n",
        "        self.downs.append(DoppiaConv(in_channels, f))\n",
        "        in_channels=f\n",
        "\n",
        "      #Up\n",
        "      for f in reversed(features):\n",
        "        self.ups.append(nn.ConvTranspose2d(f*2, f, kernel_size=2, stride=2))\n",
        "        self.ups.append(DoppiaConv(f*2,f))\n",
        "\n",
        "      #Crea un'istanza finale della classe DoppiaConv come \"collo di bottiglia\" nella parte più profonda della rete\n",
        "      #Questo strato ha il doppio del numero di canali di output rispetto all'ultimo strato nel percorso discendente.\n",
        "      self.bneck=DoppiaConv(features[-1], features[-1]*2)\n",
        "      self.f_conv=nn.Conv2d(features[0],out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      #Crea una lista vuota per memorizzare le feature map da ogni strato di downsampling (connessioni di salto).\n",
        "      skip_connections=[]\n",
        "\n",
        "      for d in self.downs:\n",
        "        x=d(x)\n",
        "        skip_connections.append(x)\n",
        "        x=self.pool(x)\n",
        "\n",
        "      x=self.bneck(x)\n",
        "      #Inverte l'ordine della lista\n",
        "      skip_connections=skip_connections[: : -1]\n",
        "\n",
        "      #percorso di salita\n",
        "      #itero a coppie\n",
        "      for idx in range(0, len(self.ups),2):\n",
        "        x=self.ups[idx](x)\n",
        "        #Recupera la connessione di salto corrispondente dalla lista skip_connections usando l'indice idx//2.\n",
        "        skip_connection=skip_connections[idx//2]\n",
        "\n",
        "        #Se le dimensioni sono diverse, utilizza un'operazione di ridimensionamento\n",
        "        if x.shape != skip_connection.shape:\n",
        "          x=TF.resize(x, size=skip_connection.shape[2:])\n",
        "\n",
        "        #Concatena le feature map di skip_connection e x lungo la dimensione del canale (dim=1)\n",
        "        #per combinare le informazioni da diversi livelli di astrazione.\n",
        "        concat_skip=torch.cat((skip_connection, x), dim=1)\n",
        "        x=self.ups[idx+1](concat_skip)\n",
        "\n",
        "      return self.f_conv(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prova senza immagini nere"
      ],
      "metadata": {
        "id": "GcAphnD8_NkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LR"
      ],
      "metadata": {
        "id": "Z7fbCFYAQCnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train e validation"
      ],
      "metadata": {
        "id": "NfYrkL_p6NdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def acc_metric(predb, yb):\n",
        "  return (predb.argmax(dim=1) == yb.cuda()).float().mean() #facendo la media si ottiene una stima più robusta e affidabile dell'accuratezza del modello."
      ],
      "metadata": {
        "id": "Vi1Is8Sx6M9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(indice, model, device, optimizer, loss_fn, lr, epochs, train_loader, val_loader, validate_filename, acc_fn, log_interval=200):\n",
        "    # Set model to train mode\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    best_f1 = -1000\n",
        "    best_model_state_dict = None\n",
        "    save_path=root+'model_'+str(indice)+'.pt'\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in  range(epochs):\n",
        "      total_loss = 0\n",
        "      accuracy = 0\n",
        "      for batch_idx, (x, target_label) in enumerate(train_loader):\n",
        "           x=x.to(device)\n",
        "           target_label=target_label.to(device)\n",
        "\n",
        "           optimizer.zero_grad()\n",
        "           output = model(x)\n",
        "           loss = loss_fn(output, target_label)\n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "\n",
        "           total_loss += loss.item()*train_loader.batch_size # in questo modo peso la loss in base al batch\n",
        "           acc = (acc_fn(output, target_label).item())*train_loader.batch_size # in questo modo peso l'accuratezza in base al batch\n",
        "           accuracy += acc\n",
        "           if batch_idx % log_interval == 0:\n",
        "              print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch,\n",
        "                    batch_idx * len(x),\n",
        "                    len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader),\n",
        "                    loss.item()\n",
        "              ))\n",
        "\n",
        "\n",
        "      train_losses.append(total_loss / len(train_loader.dataset))\n",
        "      train_acc.append(accuracy / len(train_loader.dataset))\n",
        "\n",
        "      print(f'Accuracy-> {(accuracy / len(train_loader.dataset)) * 100:.2f}%')\n",
        "\n",
        "      val_loss, val_acc, precision, recall, f1_score = validate(model, device, loss_fn, val_loader, acc_fn)\n",
        "\n",
        "      if best_f1 < f1_score:\n",
        "        best_f1 = f1_score\n",
        "        print(\"cambio best f1->\",best_f1 )\n",
        "        best_model_state_dict = model.state_dict()\n",
        "        print(\"salvataggio modello \\n\")\n",
        "        torch.save({'model_state_dict':best_model_state_dict,\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'best_f1': f1_score,\n",
        "                'epoca':epoch\n",
        "        }, save_path)\n",
        "        print(\"salvataggio avvenuto \\n\")\n",
        "\n",
        "\n",
        "      with open(validate_filename, 'a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([indice, lr,  epoch + 1, val_loss, val_acc, precision, recall, f1_score])\n",
        "\n",
        "\n",
        "    return train_losses, train_acc"
      ],
      "metadata": {
        "id": "TZm2jXSa6TIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(xss):\n",
        "    return [x for xs in xss for x in xs]"
      ],
      "metadata": {
        "id": "1UYPmmIH6W88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, device, loss_fn, validation_loader, acc_fn):\n",
        "    print(\"inizio validazione\")\n",
        "    model.eval()\n",
        "    val_loss, correct = 0, 0\n",
        "    y_pred=[]\n",
        "    y_true=[]\n",
        "    y_pred_flat=[]\n",
        "    y_true_flat=[]\n",
        "\n",
        "    # Disabilito il calcolo del gradiente per velocizzare\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for x, y in validation_loader:\n",
        "            x=x.to(device)\n",
        "            y=y.to(device)\n",
        "            # Calcolo output usando i dati come input per la rete\n",
        "            outputs = model(x)\n",
        "            loss = loss_fn(outputs, y.long())\n",
        "            # Calcolo loss usando criterion\n",
        "            val_loss += loss.item()*validation_loader.batch_size\n",
        "            # Calcolo accuratezza\n",
        "            acc = (acc_fn(outputs, y).item())*validation_loader.batch_size\n",
        "            correct += acc\n",
        "\n",
        "            y_true.extend(y.cpu().numpy()) # Converti in array numpy e appiattisci\n",
        "            y_pred.extend(outputs.squeeze().cpu().argmax(axis=1).numpy())# Converti in array numpy e appiattisci\n",
        "\n",
        "    print(\"calcolo recall, f1 e precision\")\n",
        "    y_pred_flat=flatten(y_pred)\n",
        "    y_true_flat=flatten(y_true)\n",
        "\n",
        "\n",
        "    # Calcola la media della loss e dell'accuratezza sul set di validazione\n",
        "    val_loss /= len(validation_loader.dataset)\n",
        "    accuracy = (correct / len(validation_loader.dataset))\n",
        "    accuracy=accuracy*100\n",
        "\n",
        "    precision=precision_score(y_true_flat, y_pred_flat, average='macro')\n",
        "    recall=recall_score(y_true_flat, y_pred_flat, average='macro')\n",
        "    f1=f1_score(y_true_flat, y_pred_flat, average='macro')\n",
        "\n",
        "    print('Validation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%), F1-score: {:.4f}\\n'.format(\n",
        "    val_loss,\n",
        "    correct,\n",
        "    len(validation_loader.dataset),\n",
        "    accuracy,\n",
        "    f1\n",
        "    ))\n",
        "    return val_loss, accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "WAQKp-OT6ZmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decisione Lr"
      ],
      "metadata": {
        "id": "2ImRH1ud6HXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc"
      ],
      "metadata": {
        "id": "ksFKwQkX9Yg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates1 = [1e-2, 1e-3, 1e-4, 1e-5]\n",
        "num_epochs=10\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight = torch.tensor([0.83,1]).to(device))\n",
        "#creo i due file csv dove salvo i dati\n",
        "\n",
        "results_filename = root+'training_results_detailed_nn.csv'\n",
        "validate_filename =root+ 'validate_result_nn.csv'\n",
        "\n",
        "with open(results_filename, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Indice','Learning Rate', 'Epoch', 'Train Loss', 'Train Accuracy'])\n",
        "\n",
        "with open(validate_filename, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Indice', 'Learning Rate', 'Epoch', 'Validation Loss', 'Validation Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "\n",
        "\n",
        "i=1\n",
        "\n",
        "for lr in learning_rates1:\n",
        "  print(\"inizio training per il modello con lr:\", lr)\n",
        "  model= UNET(in_channels=4, out_channels=2)\n",
        "  model=model.to(device)\n",
        "\n",
        "\n",
        "  optimizer=optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  train_losses, train_acc = train(i, model, device, optimizer, loss_fn, lr, num_epochs, train_loader, val_loader, validate_filename, acc_metric)\n",
        "\n",
        "  del model\n",
        "  del optimizer\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  with open(results_filename, 'a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        for epoch in range(num_epochs):\n",
        "            writer.writerow([i, lr,  epoch + 1, train_losses[epoch], train_acc[epoch]])\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "ua9EI2tn_NIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###grafici"
      ],
      "metadata": {
        "id": "Kr1VC3UJQIYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'training_results_detailed_nn.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "file_path = 'validate_result_nn.csv'\n",
        "dv=pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "print(df.head())\n",
        "print(dv.head())"
      ],
      "metadata": {
        "id": "ZNEhzKQtQK_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df  = pd.merge(df, dv, on=['Indice','Epoch', 'Learning Rate'])\n",
        "combined_df ['Train Accuracy'] *= 100\n",
        "\n",
        "indici = combined_df['Indice'].drop_duplicates()\n",
        "\n",
        "plt.figure(figsize=(14, 7*len(indici)))\n",
        "\n",
        "\n",
        "for i, indice  in enumerate(indici, start=1):\n",
        "    # Filtraggio dei dati per la combinazione corrente\n",
        "    filtered_df = combined_df.loc[combined_df['Indice'] == indice]\n",
        "\n",
        "    # Estrarre il learning rate corrispondente\n",
        "    lr = filtered_df['Learning Rate'].iloc[0]\n",
        "\n",
        "    # Grafico della Loss per l'indice corrente\n",
        "    plt.subplot(len(indici), 2, i*2-1)\n",
        "    plt.plot(filtered_df['Epoch'], filtered_df['Train Loss'], marker='o', label='Train Loss', color='blue')\n",
        "    plt.plot(filtered_df['Epoch'], filtered_df['Validation Loss'], marker='o', label='Validation Loss', color='orange')\n",
        "    plt.title(f'Loss (Prova {indice} LR {lr})')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Grafico dell'Accuracy per l'indice corrente\n",
        "    plt.subplot(len(indici), 2, i*2)\n",
        "    plt.plot(filtered_df['Epoch'], filtered_df['Train Accuracy'], marker='o', label='Train Accuracy', color='blue')\n",
        "    plt.plot(filtered_df['Epoch'], filtered_df['Validation Accuracy'], marker='o', label='Validation Accuracy', color='orange')\n",
        "    plt.title(f'Accuracy (Prova {indice} LR {lr})')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uL4QFJ39QaPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fondere df e dv\n",
        "combined_df = pd.merge(df, dv, on=['Indice', 'Epoch', 'Learning Rate'])\n",
        "\n",
        "# Calcolare il valore massimo di F1 per ciascun indice\n",
        "max_f1_values = combined_df.groupby('Indice')['F1'].max()\n",
        "\n",
        "# Estrarre gli indici unici\n",
        "indici = max_f1_values.index\n",
        "\n",
        "\n",
        "# Estrarre i valori di F1 massimi\n",
        "f1_values = max_f1_values.values\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(1, figsize=(10, 5))\n",
        "\n",
        "axs.bar(indici, f1_values)\n",
        "\n",
        "for i, val in enumerate(f1_values):\n",
        "    axs.text(i+1, val + 0.01, f'{val:.4f}', ha='center', va='bottom')\n",
        "\n",
        "\n",
        "\n",
        "# Titoli e etichette\n",
        "plt.title('Max F1 Values')\n",
        "plt.xlabel('Indice')\n",
        "plt.ylabel('F1')\n",
        "plt.xticks(indici)\n",
        "plt.ylim(0, max(f1_values) + 0.1)  # Impostare i limiti dell'asse y\n",
        "\n",
        "plt.grid(False)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1T2cdRj3Qt2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augumentation"
      ],
      "metadata": {
        "id": "N5y51c2YQzwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_augmentations():\n",
        "\n",
        "      transforms=[]\n",
        "      transforms.extend([\n",
        "          A.HorizontalFlip(p=0.5),\n",
        "          A.VerticalFlip(p=0.5),\n",
        "          A.RandomRotate90(p=1.0),\n",
        "\n",
        "      ])\n",
        "\n",
        "      return A.Compose(transforms)\n",
        "\n",
        "Nor=transforms.Compose([\n",
        "    transforms.Normalize(data_mean, data_std)\n",
        "])"
      ],
      "metadata": {
        "id": "S7hALGYBQ9GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set=CloudDataset1(train_file,transform=True, trasformN=Nor)\n",
        "val_set=CloudDataset1(val_file, transform=False, trasformN=Nor)"
      ],
      "metadata": {
        "id": "p_GWHYjeRAiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = data.DataLoader(train_set, batch_size=12, shuffle=True)\n",
        "val_loader = data.DataLoader(val_set, batch_size=12, shuffle=False)"
      ],
      "metadata": {
        "id": "SV7HM6-bRN2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train e validation finale"
      ],
      "metadata": {
        "id": "qfiuSrCYRQQN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train e val"
      ],
      "metadata": {
        "id": "tHIRDxg0RVWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def acc_metric(predb, yb):\n",
        "  return (predb.argmax(dim=1) == yb.cuda()).float().mean()\n",
        "def trainf(model, device, optimizer, loss_fn, lr, epochs, train_loader, val_loader, validate_filename, acc_fn, log_interval=200):\n",
        "    # Set model to train mode\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    best_f1 = -1000\n",
        "    best_model_state_dict = None\n",
        "    save_path=root+'model_finale'+str(epochs)+'_'+str(lr)+'.pt'\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in  range(epochs):\n",
        "      total_loss = 0\n",
        "      accuracy = 0\n",
        "      for batch_idx, (x, target_label) in enumerate(train_loader):\n",
        "           x=x.to(device)\n",
        "           target_label=target_label.to(device)\n",
        "\n",
        "           optimizer.zero_grad()\n",
        "           output = model(x)\n",
        "           loss = loss_fn(output, target_label)\n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "\n",
        "           total_loss += loss.item()*train_loader.batch_size\n",
        "           acc = (acc_fn(output, target_label).item())*train_loader.batch_size\n",
        "           accuracy += acc\n",
        "           if batch_idx % log_interval == 0:\n",
        "              print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch,\n",
        "                    batch_idx * len(x),\n",
        "                    len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader),\n",
        "                    loss.item()\n",
        "              ))\n",
        "\n",
        "\n",
        "      train_losses.append(total_loss / len(train_loader.dataset))\n",
        "      train_acc.append(accuracy / len(train_loader.dataset))\n",
        "\n",
        "      print(f'Accuracy-> {(accuracy / len(train_loader.dataset)) * 100:.2f}%')\n",
        "\n",
        "      val_loss, val_acc, precision, recall, f1_score = validatef(model, device, loss_fn, val_loader, acc_fn)\n",
        "\n",
        "\n",
        "      if best_f1 < f1_score:\n",
        "        best_f1 = f1_score\n",
        "        print(\"cambio best f1->\",best_f1 )\n",
        "        best_model_state_dict = model.state_dict()\n",
        "        print(\"salvataggio modello \\n\")\n",
        "        torch.save({'model_state_dict':best_model_state_dict,\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'best_f1': f1_score,\n",
        "                'epoca':epoch\n",
        "        }, save_path)\n",
        "        print(\"salvataggio avvenuto \\n\")\n",
        "\n",
        "      with open(validate_filename, 'a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([lr,  epoch + 1, val_loss, val_acc, precision, recall, f1_score])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(\"salvataggio avvennuto\")\n",
        "\n",
        "    return train_losses, train_acc"
      ],
      "metadata": {
        "id": "4i7h-GuZRaCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(xss):\n",
        "    return [x for xs in xss for x in xs]"
      ],
      "metadata": {
        "id": "np3R5iyJRUxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validatef(model, device, loss_fn, validation_loader, acc_fn):\n",
        "    print(\"inizio validazione->\")\n",
        "    model.eval()\n",
        "    val_loss, correct = 0, 0\n",
        "    y_pred=[]\n",
        "    y_true=[]\n",
        "    y_pred_flat=[]\n",
        "    y_true_flat=[]\n",
        "\n",
        "    # Disabilito il calcolo del gradiente per velocizzare\n",
        "    with torch.no_grad():\n",
        "        # Loop over each batch from the validation set\n",
        "        for x, y in validation_loader:\n",
        "            x=x.to(device)\n",
        "            y=y.to(device)\n",
        "            # Calcolo output usando i dati come input per la rete\n",
        "            outputs = model(x)\n",
        "\n",
        "            loss = loss_fn(outputs, y.long())\n",
        "\n",
        "            # Calcolo loss usando criterion\n",
        "            val_loss += loss.item()*validation_loader.batch_size\n",
        "            # Calcolo accuratezza\n",
        "            acc = (acc_fn(outputs, y).item())*validation_loader.batch_size\n",
        "            correct += acc\n",
        "\n",
        "            y_true.extend(y.cpu().numpy()) # Converti in array numpy e appiattisci\n",
        "            y_pred.extend(outputs.squeeze().cpu().argmax(axis=1).numpy())# Converti in array numpy e appiattisci\n",
        "\n",
        "    print(\"calcolo recall, f1 e precision\")\n",
        "    y_pred_flat=flatten(y_pred)\n",
        "\n",
        "\n",
        "    y_true_flat=flatten(y_true)\n",
        "\n",
        "    val_loss /= len(validation_loader.dataset)\n",
        "    accuracy = (correct / len(validation_loader.dataset))\n",
        "    accuracy=accuracy*100\n",
        "\n",
        "\n",
        "    precision=precision_score(y_true_flat, y_pred_flat, average='macro')\n",
        "    recall=recall_score(y_true_flat, y_pred_flat, average='macro')\n",
        "    f1=f1_score(y_true_flat, y_pred_flat, average='macro')\n",
        "\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%), F1-score: {:.4f}\\n'.format(\n",
        "    val_loss,\n",
        "    correct,\n",
        "    len(validation_loader.dataset),\n",
        "    accuracy,\n",
        "    f1\n",
        "    ))\n",
        "    return val_loss, accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "VlDUbOizRePe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Esecuzione"
      ],
      "metadata": {
        "id": "GnYJYrSJSRkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "primo tentativo con pesi e lr=1e-5"
      ],
      "metadata": {
        "id": "1Tv2WQSFA-XW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-5\n",
        "num_epochs=10\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight = torch.tensor([0.83,1]).to(device))\n",
        "#creo i due file csv dove salvo i dati\n",
        "\n",
        "results_filename = root+'training_results_detailed_10.csv'\n",
        "validate_filename =root+ 'validate_result_10.csv'\n",
        "\n",
        "with open(results_filename, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Learning Rate', 'Epoch', 'Train Loss', 'Train Accuracy'])\n",
        "\n",
        "with open(validate_filename, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Learning Rate', 'Epoch', 'Validation Loss', 'Validation Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "\n",
        "\n",
        "\n",
        "print(\"inizio training per il modello con lr:\", lr)\n",
        "model= UNET(in_channels=4, out_channels=2)\n",
        "model=model.to(device)\n",
        "optimizer=optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "train_losses, train_acc = trainf(model, device, optimizer, loss_fn, lr, num_epochs, train_loader, val_loader, validate_filename, acc_metric)\n",
        "\n",
        "del model\n",
        "del optimizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "with open(results_filename, 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      for epoch in range(num_epochs):\n",
        "           writer.writerow([lr,  epoch + 1, train_losses[epoch], train_acc[epoch]])"
      ],
      "metadata": {
        "id": "S3eAR87NSUiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "senza pesi"
      ],
      "metadata": {
        "id": "p2RZkW7vBF6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-5\n",
        "num_epochs=11\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "#creo i due file csv dove salvo i dati\n",
        "\n",
        "results_filename = root+'training_results_detailed_11.csv'\n",
        "validate_filename =root+ 'validate_result_11.csv'\n",
        "\n",
        "with open(results_filename, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Learning Rate', 'Epoch', 'Train Loss', 'Train Accuracy'])\n",
        "\n",
        "with open(validate_filename, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Learning Rate', 'Epoch', 'Validation Loss', 'Validation Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "\n",
        "\n",
        "\n",
        "print(\"inizio training per il modello con lr:\", lr)\n",
        "model= UNET(in_channels=4, out_channels=2)\n",
        "model=model.to(device)\n",
        "optimizer=optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "train_losses, train_acc = trainf(model, device, optimizer, loss_fn, lr, num_epochs, train_loader, val_loader, validate_filename, acc_metric)\n",
        "\n",
        "del model\n",
        "del optimizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "with open(results_filename, 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      for epoch in range(num_epochs):\n",
        "           writer.writerow([lr,  epoch + 1, train_losses[epoch], train_acc[epoch]])"
      ],
      "metadata": {
        "id": "tY20S7OEvEta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "provo con un lr diverso"
      ],
      "metadata": {
        "id": "TnZsCmLTC1kO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0001\n",
        "num_epochs=10\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight = torch.tensor([0.83,1]).to(device))\n",
        "#creo i due file csv dove salvo i dati\n",
        "\n",
        "results_filename = root+'training_results_detailed_10_1.csv'\n",
        "validate_filename =root+ 'validate_result_10_1.csv'\n",
        "\n",
        "with open(results_filename, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Learning Rate', 'Epoch', 'Train Loss', 'Train Accuracy'])\n",
        "\n",
        "with open(validate_filename, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Learning Rate', 'Epoch', 'Validation Loss', 'Validation Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "\n",
        "\n",
        "\n",
        "print(\"inizio training per il modello con lr:\", lr)\n",
        "model= UNET(in_channels=4, out_channels=2)\n",
        "model=model.to(device)\n",
        "optimizer=optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "train_losses, train_acc = trainf(model, device, optimizer, loss_fn, lr, num_epochs, train_loader, val_loader, validate_filename, acc_metric)\n",
        "\n",
        "del model\n",
        "del optimizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "with open(results_filename, 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      for epoch in range(num_epochs):\n",
        "           writer.writerow([lr,  epoch + 1, train_losses[epoch], train_acc[epoch]])"
      ],
      "metadata": {
        "id": "W9j8X0gewtBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grafici"
      ],
      "metadata": {
        "id": "NuSwXt63wCKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = root+'training_results_detailed_10.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "file_path = root+'validate_result_10.csv'\n",
        "dv=pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "print(df.head())\n",
        "print(dv.head())"
      ],
      "metadata": {
        "id": "He_Ae_Opws_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df  = pd.merge(df, dv, on=['Epoch', 'Learning Rate'])\n",
        "combined_df ['Train Accuracy'] *= 100\n",
        "\n",
        "epoche = combined_df['Epoch'].drop_duplicates()\n",
        "\n",
        "plt.figure(figsize=(10, 14))\n",
        "\n",
        "\n",
        "# Grafico della Loss per l'indice corrente\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(combined_df['Epoch'], combined_df['Train Loss'], marker='o', label='Train Loss', color='blue')\n",
        "plt.plot(combined_df['Epoch'], combined_df['Validation Loss'], marker='o', label='Validation Loss', color='orange')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.grid(True)\n",
        "\n",
        " # Grafico dell'Accuracy per l'indice corrente\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(combined_df['Epoch'], combined_df['Train Accuracy'], marker='o', label='Train Accuracy', color='blue')\n",
        "plt.plot(combined_df['Epoch'], combined_df['Validation Accuracy'], marker='o', label='Validation Accuracy', color='orange')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CqleoGdEwEGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = dv['Epoch'].unique()  # Prendi gli epoch univoci\n",
        "\n",
        "plt.figure(figsize=(10, 14))\n",
        "\n",
        "# Grafico del F1-score\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(dv['Epoch'], dv['F1'], marker='o', color='green')\n",
        "plt.title('F1-score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('F1-score')\n",
        "plt.grid(True)\n",
        "\n",
        "# Grafico del Recall\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(dv['Epoch'], dv['Recall'], marker='o', color='red')\n",
        "plt.title('Recall')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Recall')\n",
        "plt.grid(True)\n",
        "\n",
        "# Grafico della Precision\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(dv['Epoch'], dv['Precision'], marker='o', color='blue')\n",
        "plt.title('Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j4JRdyaPxHVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = root+'training_results_detailed_11.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "file_path = root+'validate_result_11.csv'\n",
        "dv=pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "print(df.head())\n",
        "print(dv.head())"
      ],
      "metadata": {
        "id": "HgLnPD791WJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df  = pd.merge(df, dv, on=['Epoch', 'Learning Rate'])\n",
        "combined_df ['Train Accuracy'] *= 100\n",
        "\n",
        "epoche = combined_df['Epoch'].drop_duplicates()\n",
        "\n",
        "plt.figure(figsize=(10, 14))\n",
        "\n",
        "\n",
        "# Grafico della Loss per l'indice corrente\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(combined_df['Epoch'], combined_df['Train Loss'], marker='o', label='Train Loss', color='blue')\n",
        "plt.plot(combined_df['Epoch'], combined_df['Validation Loss'], marker='o', label='Validation Loss', color='orange')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.grid(True)\n",
        "\n",
        " # Grafico dell'Accuracy per l'indice corrente\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(combined_df['Epoch'], combined_df['Train Accuracy'], marker='o', label='Train Accuracy', color='blue')\n",
        "plt.plot(combined_df['Epoch'], combined_df['Validation Accuracy'], marker='o', label='Validation Accuracy', color='orange')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z3HhHNBZ1ZCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = dv['Epoch'].unique()  # Prendi gli epoch univoci\n",
        "\n",
        "plt.figure(figsize=(10, 14))\n",
        "\n",
        "# Grafico del F1-score\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(dv['Epoch'], dv['F1'], marker='o', color='green')\n",
        "plt.title('F1-score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('F1-score')\n",
        "plt.grid(True)\n",
        "\n",
        "# Grafico del Recall\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(dv['Epoch'], dv['Recall'], marker='o', color='red')\n",
        "plt.title('Recall')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Recall')\n",
        "plt.grid(True)\n",
        "\n",
        "# Grafico della Precision\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(dv['Epoch'], dv['Precision'], marker='o', color='blue')\n",
        "plt.title('Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nATMhODm1a-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = root+'training_results_detailed_10_1.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "file_path = root+'validate_result_10_1.csv'\n",
        "dv=pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "print(dv.head())\n",
        "combined_df  = pd.merge(df, dv, on=['Epoch', 'Learning Rate'])\n",
        "combined_df ['Train Accuracy'] *= 100\n",
        "\n",
        "epoche = combined_df['Epoch'].drop_duplicates()\n",
        "\n",
        "plt.figure(figsize=(10, 14))\n",
        "\n",
        "\n",
        "# Grafico della Loss per l'indice corrente\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(combined_df['Epoch'], combined_df['Train Loss'], marker='o', label='Train Loss', color='blue')\n",
        "plt.plot(combined_df['Epoch'], combined_df['Validation Loss'], marker='o', label='Validation Loss', color='orange')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.grid(True)\n",
        "\n",
        " # Grafico dell'Accuracy per l'indice corrente\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(combined_df['Epoch'], combined_df['Train Accuracy'], marker='o', label='Train Accuracy', color='blue')\n",
        "plt.plot(combined_df['Epoch'], combined_df['Validation Accuracy'], marker='o', label='Validation Accuracy', color='orange')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j2ZCRBcURPmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = dv['Epoch'].unique()  # Prendi gli epoch univoci\n",
        "\n",
        "plt.figure(figsize=(10, 14))\n",
        "\n",
        "# Grafico del F1-score\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(dv['Epoch'], dv['F1'], marker='o', color='green')\n",
        "plt.title('F1-score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('F1-score')\n",
        "plt.grid(True)\n",
        "\n",
        "# Grafico del Recall\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(dv['Epoch'], dv['Recall'], marker='o', color='red')\n",
        "plt.title('Recall')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Recall')\n",
        "plt.grid(True)\n",
        "\n",
        "# Grafico della Precision\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(dv['Epoch'], dv['Precision'], marker='o', color='blue')\n",
        "plt.title('Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DoDtg1QCRgc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predizioni"
      ],
      "metadata": {
        "id": "b4zUz4LXwLZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_to_img(xb, idx):\n",
        "    img = np.array(xb[idx, 0:3].cpu())\n",
        "    img = img.transpose((1, 2, 0))  # Trasponi per avere (H, W, C)\n",
        "\n",
        "    # Normalizza l'immagine per essere compresa tra 0 e 1\n",
        "    img_min = img.min()\n",
        "    img_max = img.max()\n",
        "    if img_max > img_min:  # Evita la divisione per zero\n",
        "        img = (img - img_min) / (img_max - img_min)\n",
        "    return img"
      ],
      "metadata": {
        "id": "IaiHi5k_yfH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNET(in_channels=4, out_channels=2)\n",
        "model1= UNET(in_channels=4, out_channels=2)\n",
        "checkpoint = torch.load(root+'model_finale10.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "checkpoint1 = torch.load(root+'model_finale11.pt')\n",
        "model1.load_state_dict(checkpoint1['model_state_dict'])\n",
        "model.to(device)\n",
        "model1.to(device)\n",
        "bs = 8\n",
        "val_loader_iter = iter(val_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(25):  # Visualizza i risultati per 7 batch\n",
        "        xb, yb = next(val_loader_iter)\n",
        "        predb = model(xb.to(device))\n",
        "        predb1 = model1(xb.to(device))\n",
        "\n",
        "        fig, ax = plt.subplots(8, 4 , figsize=(15,bs*5))\n",
        "        for i in range(bs):\n",
        "            ax[i,0].imshow(batch_to_img(xb,i))\n",
        "            ax[i,1].imshow(yb[i])\n",
        "            ax[i,2].imshow(predb_to_mask(predb, i))\n",
        "            ax[i,3].imshow(predb_to_mask(predb1, i))\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "O2LZ-j--6Pdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNET(in_channels=4, out_channels=2)\n",
        "checkpoint = torch.load(root+'model_finale10_0.0001.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.to(device)\n",
        "bs = 12\n",
        "val_loader_iter = iter(val_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(2):  # Visualizza i risultati per 7 batch\n",
        "        xb, yb = next(val_loader_iter)\n",
        "        predb = model(xb.to(device))\n",
        "\n",
        "        fig, ax = plt.subplots(12, 3 , figsize=(15,bs*5))\n",
        "        for i in range(bs):\n",
        "            ax[i,0].imshow(batch_to_img(xb,i))\n",
        "            ax[i,1].imshow(yb[i])\n",
        "            ax[i,2].imshow(predb_to_mask(predb, i))\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "skSsVjs_Q2IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNET(in_channels=4, out_channels=2)\n",
        "model1= UNET(in_channels=4, out_channels=2)\n",
        "checkpoint = torch.load(root+'model_finale10.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "checkpoint1 = torch.load(root+'model_finale10_0.0001.pt')\n",
        "model1.load_state_dict(checkpoint1['model_state_dict'])\n",
        "model.to(device)\n",
        "model1.to(device)\n",
        "bs = 12\n",
        "val_loader_iter = iter(val_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(5):  # Visualizza i risultati per 7 batch\n",
        "        xb, yb = next(val_loader_iter)\n",
        "        predb = model(xb.to(device))\n",
        "        predb1 = model1(xb.to(device))\n",
        "\n",
        "        fig, ax = plt.subplots(12, 4 , figsize=(15,bs*5))\n",
        "        for i in range(bs):\n",
        "            ax[i,0].imshow(batch_to_img(xb,i))\n",
        "            ax[i,1].imshow(yb[i])\n",
        "            ax[i,2].imshow(predb_to_mask(predb, i))\n",
        "            ax[i,3].imshow(predb_to_mask(predb1, i))\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "MMQ5IsyVRtcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNET(in_channels=4, out_channels=2)\n",
        "model1= UNET(in_channels=4, out_channels=2)\n",
        "checkpoint = torch.load(root+'model_finale10.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "checkpoint1 = torch.load('model_pesi.pt')\n",
        "model1.load_state_dict(checkpoint1['model_state_dict'])\n",
        "model.to(device)\n",
        "model1.to(device)\n",
        "bs = 12\n",
        "val_loader_iter = iter(val_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(5):  # Visualizza i risultati per 7 batch\n",
        "        xb, yb = next(val_loader_iter)\n",
        "        predb = model(xb.to(device))\n",
        "        predb1 = model1(xb.to(device))\n",
        "\n",
        "        fig, ax = plt.subplots(12, 4 , figsize=(15,bs*5))\n",
        "        for i in range(bs):\n",
        "            ax[i,0].imshow(batch_to_img(xb,i))\n",
        "            ax[i,1].imshow(yb[i])\n",
        "            ax[i,2].imshow(predb_to_mask(predb, i))\n",
        "            ax[i,3].imshow(predb_to_mask(predb1, i))\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "wyE74OR8Sep0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "eNH836QHZcSy",
        "48SyD-Gg_Xry",
        "FT_WjfIfGbEt",
        "46ISYHVd7DMv",
        "NfYrkL_p6NdB",
        "2ImRH1ud6HXW",
        "Kr1VC3UJQIYy",
        "tHIRDxg0RVWl"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}